{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8cDtxLIBHgQ",
    "outputId": "b1bb2281-f9e6-45af-fec4-f95ed2404792"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjpPg4mGKc1v",
    "outputId": "506a6a19-22a5-415c-a02d-4e4d17dccf30"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C3EO_2zNChu"
   },
   "source": [
    "## Install YOLOv8\n",
    "\n",
    "‚ö†Ô∏è YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **18.01.2023** with version **YOLOv8.0.9**.\n",
    "\n",
    "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
    "\n",
    "YOLOv8 can be installed in two ways‚Ää-‚Ääfrom the source and via pip. This is because it is the first iteration of YOLO to have an official package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdSMcABDNKW-",
    "outputId": "b7e777a1-8a18-4be0-9812-0a7910f0c6c2"
   },
   "outputs": [],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics==8.0.20\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOEYrlBoP9-E"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnnZSm5OQfPQ"
   },
   "source": [
    "## CLI Basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K33S7zlkQku0"
   },
   "source": [
    "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://v8docs.ultralytics.com/cli/).\n",
    "\n",
    "```\n",
    "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
    "          classify       predict        yolov8n-cls.yaml  args...\n",
    "          segment        val            yolov8n-seg.yaml  args...\n",
    "                         export         yolov8n.pt        format=onnx  args...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5RGYA6sPgEd"
   },
   "source": [
    "## Inference with Pre-trained COCO Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT1qD4toTTw0"
   },
   "source": [
    "### üíª CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaE1kLS8R4CV"
   },
   "source": [
    "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDbMt_M6PiXb",
    "outputId": "db49b609-cfb3-4773-e4e6-81614d111b7b"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyopYpK1TQrB"
   },
   "outputs": [],
   "source": [
    "# %cd {HOME}\n",
    "# Image(filename='runs/detect/predict/dog.jpeg', height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFMBYQtMVL-B"
   },
   "source": [
    "### üêç Python SDK\n",
    "\n",
    "The simplest way of simply using YOLOv8 directly in a Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rx9NWF-sVN6Y",
    "outputId": "42c68241-8b5a-4597-d5f0-e6a7867f4a79"
   },
   "outputs": [],
   "source": [
    "model = YOLO(f'{HOME}/yolov8n.pt')\n",
    "results = model.predict(source='https://media.roboflow.com/notebooks/examples/dog.jpeg', conf=0.25, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kAi4PvrItTCf",
    "outputId": "6d5e0223-b5ad-4b40-8094-854c7c6c4e63"
   },
   "outputs": [],
   "source": [
    "results[0].boxes.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqT2M01K1LUb",
    "outputId": "a33586ac-fe54-48a3-f52e-675a3197e13e"
   },
   "outputs": [],
   "source": [
    "results[0].boxes.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKIwJ5yw1PMb",
    "outputId": "e31f0368-787e-4749-81bb-2c0a636026d9"
   },
   "outputs": [],
   "source": [
    "results[0].boxes.cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUjFBKKqXa-u"
   },
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ultralytics torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_di00JWpOX8",
    "outputId": "e5dd734d-7a62-4b11-a46b-ebbd6ad8d669"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "label_dir = 'C:\\\\Users\\\\HP\\\\Desktop\\\\fall\\\\tree.fall-1\\\\train\\\\labels'  # Update this with your labels directory\n",
    "\n",
    "for label_file in os.listdir(label_dir):\n",
    "    if label_file.endswith('.txt'):\n",
    "        with open(os.path.join(label_dir, label_file)) as f:\n",
    "            for line in f:\n",
    "                parts = line.split()\n",
    "                if parts:  # Check if line is not empty\n",
    "                    try:\n",
    "                        # Attempt to convert the first part to int\n",
    "                        class_id = int(parts[0])\n",
    "                    except ValueError:\n",
    "                        print(f\"Invalid class id in {label_file}: '{parts[0]}' in line: '{line.strip()}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hadnMgv2pahh",
    "outputId": "fa0dd8af-4ba5-4573-d2a1-a070f97a63fd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.101 √∞≈∏≈°‚Ç¨ Python-3.12.4 torch-2.4.1+cu118 CPU (13th Gen Intel Core(TM) i7-13620H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data.yaml, epochs=25, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\HP\\Desktop\\fall\\tree.fall-1\\train\\labels.cache... 289 images, 0 backgrounds, 0 corrupt: 100%|##########| 289/289 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\HP\\Desktop\\fall\\tree.fall-1\\train\\labels.cache... 289 images, 0 backgrounds, 0 corrupt: 100%|##########| 289/289 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\HP\\Desktop\\fall\\tree.fall-1\\valid\\labels.cache... 135 images, 0 backgrounds, 0 corrupt: 100%|##########| 135/135 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\HP\\Desktop\\fall\\tree.fall-1\\valid\\labels.cache... 135 images, 0 backgrounds, 0 corrupt: 100%|##########| 135/135 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      "       1/25         0G      2.669      3.219      2.297         37        224:   0%|          | 0/19 [00:06<?, ?it/s]\n",
      "       1/25         0G      2.669      3.219      2.297         37        224:   5%|5         | 1/19 [00:06<01:52,  6.25s/it]\n",
      "       1/25         0G      2.815      3.322      2.322         43        224:   5%|5         | 1/19 [00:12<01:52,  6.25s/it]\n",
      "       1/25         0G      2.815      3.322      2.322         43        224:  11%|#         | 2/19 [00:12<01:42,  6.01s/it]\n",
      "       1/25         0G      2.647      3.258      2.223         35        224:  11%|#         | 2/19 [00:18<01:42,  6.01s/it]\n",
      "       1/25         0G      2.647      3.258      2.223         35        224:  16%|#5        | 3/19 [00:18<01:39,  6.19s/it]\n",
      "       1/25         0G       2.69      3.287      2.275         37        224:  16%|#5        | 3/19 [00:23<01:39,  6.19s/it]\n",
      "       1/25         0G       2.69      3.287      2.275         37        224:  21%|##1       | 4/19 [00:23<01:26,  5.74s/it]\n",
      "       1/25         0G      2.656      3.256      2.231         39        224:  21%|##1       | 4/19 [00:29<01:26,  5.74s/it]\n",
      "       1/25         0G      2.656      3.256      2.231         39        224:  26%|##6       | 5/19 [00:29<01:22,  5.87s/it]\n",
      "       1/25         0G      2.662      3.341      2.205         29        224:  26%|##6       | 5/19 [00:36<01:22,  5.87s/it]\n",
      "       1/25         0G      2.662      3.341      2.205         29        224:  32%|###1      | 6/19 [00:36<01:19,  6.14s/it]\n",
      "       1/25         0G      2.627      3.248      2.193         37        224:  32%|###1      | 6/19 [00:42<01:19,  6.14s/it]\n",
      "       1/25         0G      2.627      3.248      2.193         37        224:  37%|###6      | 7/19 [00:42<01:14,  6.19s/it]\n",
      "       1/25         0G      2.655      3.234      2.195         43        224:  37%|###6      | 7/19 [00:49<01:14,  6.19s/it]\n",
      "       1/25         0G      2.655      3.234      2.195         43        224:  42%|####2     | 8/19 [00:49<01:09,  6.31s/it]\n",
      "       1/25         0G      2.649      3.164      2.174         37        224:  42%|####2     | 8/19 [00:55<01:09,  6.31s/it]\n",
      "       1/25         0G      2.649      3.164      2.174         37        224:  47%|####7     | 9/19 [00:55<01:03,  6.39s/it]\n",
      "       1/25         0G      2.615      3.101      2.147         36        224:  47%|####7     | 9/19 [01:02<01:03,  6.39s/it]\n",
      "       1/25         0G      2.615      3.101      2.147         36        224:  53%|#####2    | 10/19 [01:02<00:58,  6.55s/it]\n",
      "       1/25         0G      2.593      3.047      2.132         33        224:  53%|#####2    | 10/19 [01:08<00:58,  6.55s/it]\n",
      "       1/25         0G      2.593      3.047      2.132         33        224:  58%|#####7    | 11/19 [01:08<00:51,  6.39s/it]\n",
      "       1/25         0G      2.572      3.012      2.115         37        224:  58%|#####7    | 11/19 [01:14<00:51,  6.39s/it]\n",
      "       1/25         0G      2.572      3.012      2.115         37        224:  63%|######3   | 12/19 [01:14<00:44,  6.36s/it]\n",
      "       1/25         0G      2.551      2.951      2.096         33        224:  63%|######3   | 12/19 [01:21<00:44,  6.36s/it]\n",
      "       1/25         0G      2.551      2.951      2.096         33        224:  68%|######8   | 13/19 [01:21<00:38,  6.45s/it]\n",
      "       1/25         0G      2.517      2.896      2.069         31        224:  68%|######8   | 13/19 [01:27<00:38,  6.45s/it]\n",
      "       1/25         0G      2.517      2.896      2.069         31        224:  74%|#######3  | 14/19 [01:27<00:31,  6.34s/it]\n",
      "       1/25         0G      2.494      2.871      2.059         46        224:  74%|#######3  | 14/19 [01:33<00:31,  6.34s/it]\n",
      "       1/25         0G      2.494      2.871      2.059         46        224:  79%|#######8  | 15/19 [01:33<00:24,  6.17s/it]\n",
      "       1/25         0G      2.494      2.871      2.059         46        224:  79%|#######8  | 15/19 [01:35<00:25,  6.37s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 831, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 803, in train\n",
      "    self.trainer.train()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 207, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 385, in _do_train\n",
      "    self.loss, self.loss_items = self.model(batch)\n",
      "                                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 107, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 289, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\loss.py\", line 232, in __call__\n",
      "    _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
      "                                                  ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 72, in forward\n",
      "    mask_pos, align_metric, overlaps = self.get_pos_mask(\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 94, in get_pos_mask\n",
      "    align_metric, overlaps = self.get_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 113, in get_box_metrics\n",
      "    bbox_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  # b, max_num_obj, h*w\n",
      "                           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "IndexError: index 2 is out of bounds for dimension 1 with size 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change to your desired working directory\n",
    "os.chdir('C:\\\\Users\\\\HP\\\\Desktop\\\\fall')\n",
    "\n",
    "# Run YOLO training on CPU\n",
    "!yolo task=detect mode=train model=yolov8s.pt data=data.yaml epochs=25 imgsz=224 plots=True device=cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2YkphuiaE7_",
    "outputId": "41f751df-c3d2-40ab-8911-1075d953a88d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MScstfHhArr",
    "outputId": "6234125f-cc5e-4d76-d3c6-ae9c60ef7ba2"
   },
   "outputs": [],
   "source": [
    "!lr/ runs/detect/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "_J35i8Ofhjxa",
    "outputId": "1e55f36d-94db-4ff7-a0ae-2e43e4c076fb"
   },
   "outputs": [],
   "source": [
    "Image(filename='runs/detect/train2/confusion_matrix.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "A-urTWUkhRmn",
    "outputId": "b3f539d3-8cff-4d9b-928c-6c6d3cc11b93"
   },
   "outputs": [],
   "source": [
    "Image(filename='runs/detect/train2/results.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "HI4nADCCj3F5",
    "outputId": "0f7f34bf-b1a5-4771-ddd4-e76155f3659f"
   },
   "outputs": [],
   "source": [
    "Image(filename='runs/detect/train2/val_batch0_pred.jpg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ODk1VTlevxn"
   },
   "source": [
    "## Validate Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpyuwrNlXc1P",
    "outputId": "45b46859-ecb4-4c2c-d1f5-ed23f8d703ee"
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode=val model=runs/detect/train2/weights/best.pt data=data.yaml device='cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4eASbcWkQBq"
   },
   "source": [
    "## Inference with Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wjc1ctZykYuf",
    "outputId": "b722bbbe-ece3-4b91-f804-5fc3798d1210"
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=runs/detect/train2/weights/best.pt conf=0.25 source=data/test/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEYIo95n-I0S"
   },
   "source": [
    "**NOTE:** Let's take a look at few results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbVjEtPAkz3j"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob('runs/detect/predict/*.jpg')[:3]:\n",
    "      display(Image(filename=image_path, width=600))\n",
    "      print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
